{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Project Summer Analytics 2020\n",
    "===============================================================  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall: Stage 01: Observation of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% RUN %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "# 1.1) Importing Libraries\n",
    "# ==========================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import sklearn \n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, LabelEncoder, OneHotEncoder\n",
    "# from sklearn.preprocessing import Imputer\n",
    "# from imblearn.over_sampling import SMOTE\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.stats import randint\n",
    "from IPython.display import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1.2) Loading Training set data\n",
    "# ================================\n",
    "df_train = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dropping all these 4 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% RUN %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "\n",
    "# Droping 'Id', 'Behaviour', 'EmployeeNumber' and 'PerformanceRating' columns\n",
    "df_train.drop(['Id', 'Behaviour', 'EmployeeNumber', 'PerformanceRating'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% RUN %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, LabelEncoder, OneHotEncoder\n",
    "# from sklearn.preprocessing import Imputer\n",
    "# from imblearn.over_sampling import SMOTE\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.stats import randint\n",
    "from IPython.display import Image\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.1.2) Lable Encoder\n",
    "Transform non-numeric columns to numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% RUN %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "df_train3 = df_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% RUN %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# creating instance of labelencoder\n",
    "LE = LabelEncoder()\n",
    "\n",
    "# Transforming non-numeric columns into numerical columns in Training Data Frame\n",
    "for column in df_train3.columns:\n",
    "    if df_train3[column].dtype == object:\n",
    "        df_train3[column] = LE.fit_transform(df_train3[column])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% RUN %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "\n",
    "Y = df_train3['Attrition']\n",
    "X = df_train3.drop(['Attrition'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% RUN %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Feature Scaling\n",
    "std_sclr = StandardScaler()\n",
    "X_scale = std_sclr.fit_transform(X)\n",
    "X_scale = pd.DataFrame(X_scale,columns=X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Splitting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% RUN %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "X_train_scale, X_test_scale, Y_train, Y_test = train_test_split(X_scale, Y, test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Principal Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% RUN %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "pca = PCA(n_components = None)\n",
    "X_train_pca = pca.fit_transform(X_train_scale)\n",
    "X_test_pca = pca.transform(X_test_scale)\n",
    "explained_variance = pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% RUN %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "pca_explained_variance = pd.DataFrame(list(explained_variance), columns=['explained_variance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 792x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% RUN %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "\n",
    "fig = plt.figure(figsize=(11,6))\n",
    "pca_explained_variance['explained_variance'].plot(kind = 'bar', stacked = True, colormap = 'winter', rot = 0)\n",
    "plt.xlabel('PCA Componants', fontsize = 'x-large')\n",
    "plt.ylabel('Variance', fontsize = 'x-large')\n",
    "plt.title('Principal Componant Analysis', fontsize = 'x-large')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 06: Applying Machine Learning Algorithms\n",
    "### ========================================\n",
    "\n",
    "Since we must predict a binary class, we will be using classification models for training & predicting Employee Attrition. We need to keep in mind that our focus should be to have a better accuracy of predicting attrition i.e. Attrition = 1 which in confusion matrix will be \"True Positive\". However, we should not forget the prediction accuracy of not qualifying for attrition i.e. Attrition = 0 which will be \"True Negative\" in confusion matrix.\n",
    "\n",
    "In this section; Logistic Regression, Decision Tree Classification, Random Forest Classification, K-NN Classification, Support Vector Machine (SVM) Classification, Kernel Support Vector Machine (SVM) Classification, Na√Øve Bayes Classification, Gradient Boosting Classification, and ADA Boost Classification algorithms are applied to the dataset.\n",
    "\n",
    "I will apply these algorithms into all features available and also features which explain the 90% of total importance via PCA. I will also try to improve model accuracy via hyperparameter tuning. I have coded four functions to apply to the models throughout this section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% RUN %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "\n",
    "# Model selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Import the necessary modelling algos.\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% RUN %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "# Loading the testing data\n",
    "df_test_org = pd.read_csv('test.csv')\n",
    "\n",
    "# Droping the columns which don't effect the target column\n",
    "df_test = df_test_org.drop(['Id', 'Behaviour', 'EmployeeNumber', 'PerformanceRating'], axis=1)\n",
    "\n",
    "# Applying Lable encoding\n",
    "# ===========================\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "LE = LabelEncoder()\n",
    "\n",
    "# Transforming non-numeric columns into numerical columns in Training Data Frame\n",
    "for column in df_test.columns:\n",
    "    if df_test[column].dtype == object:\n",
    "        df_test[column] = LE.fit_transform(df_test[column])\n",
    "\n",
    "# Applying Feature Scaling\n",
    "# ===========================\n",
    "std_sclr = StandardScaler()\n",
    "df_test_scale = std_sclr.fit_transform(df_test)\n",
    "df_test_scale = pd.DataFrame(df_test_scale, columns=df_test.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(470, 24)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_scale.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying PCA by Extracting 24 features\n",
    "# ==================================\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 24)\n",
    "df_test_pca = pd.DataFrame(pca.fit_transform(df_test_scale))\n",
    "df_test_pca.columns = df_test_scale.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Classification Functions for Machine Learning Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Classification Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% RUN %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "# Creating temporary dataframe for storing ID and ATTRITION values into csv file.\n",
    "sample_submission = df_test_org[['Id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% RUN %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "# Creating data frame to store score values of models\n",
    "compare_scores = pd.DataFrame(np.full((9,4), 0.0), \n",
    "                   index = ['LogisticRegression', 'DecisionTreeClassifier', 'RandomForestClassifier','KNeighborsClassifier','SVM','KernelSVM', 'GaussianNB', 'GradientBoostingClassifier',  'AdaBoostClassifier'], \n",
    "                   columns = ['all_features', 'tuned_all_features', 'PCA_features', 'tuned_PCA_features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% RUN %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "\n",
    "def classification_model(X_train_set, X_test_set, df_test_set, Model, Model_string, col, bst_prms):\n",
    "    \n",
    "     # TRAINING DATA ======================================================================================================\n",
    "            # Fitting/Training classifier to the Training data set\n",
    "    Model.fit(X_train_set, Y_train)\n",
    "    \n",
    "    # VALIDATING ======================================================================================================\n",
    "            # Finding evaluation metric (f1-score), storing it into a data frame ('score') and  Printing. \n",
    "    Y_test_set_pred = Model.predict(X_test_set)\n",
    "    score = f1_score(Y_test, Y_test_set_pred, average = 'weighted')\n",
    "    compare_scores[col][Model_string] = score\n",
    "            # Printing the score\n",
    "    print(\"f1 score: {}\".format(score)) \n",
    "          # Printing the Confusion Matrix\n",
    "    print('Confusion Matrix is:\\n', confusion_matrix(Y_test, Y_test_set_pred)) \n",
    "    \n",
    "    # ======================================================================================================\n",
    "            # Printing Tuned Model Parameters\n",
    "    if bst_prms == 'YES':\n",
    "        print(\"Tuned Model Parameters: {}\".format(Model.best_params_))\n",
    "        \n",
    "    # CREATING CSV FILE ======================================================================================================\n",
    "            # Predicting the required testing set and storing into data frame\n",
    "    df_test_set_pred = Model.predict(df_test_set)\n",
    "    sample_submission['Attrition_val'] = df_test_set_pred\n",
    "    \n",
    "            # Predicting the probabilities for the df_test data and storing into data frame\n",
    "    df_test_set_pred_prob = Model.predict_proba(df_test_set)\n",
    "    sample_submission['Attrition_prob_0'] = df_test_set_pred_prob[:, 0]\n",
    "    sample_submission['Attrition_prob_1'] = df_test_set_pred_prob[:, 1]\n",
    "\n",
    "            # Exporting Dataframe into csv file\n",
    "    csv_file_name = 'sample_submission_' + Model_string + '_' + col + '.csv'\n",
    "    sample_submission.to_csv(csv_file_name, index=False)\n",
    "    print('CSV file is created successfully')\n",
    "    # ======================================================================================================\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#                                          ===========   =========== Applying Models =========== ==========="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 - Logistic Regression\n",
    "##### ==================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.1.1 - Logistic Regression with all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.7420303166024437\n",
      "Confusion Matrix is:\n",
      " [[150  50]\n",
      " [ 55 152]]\n",
      "CSV file is created successfully\n"
     ]
    }
   ],
   "source": [
    "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% RUN %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "\n",
    "# Function for logistic regression with all features\n",
    "Model = LogisticRegression(random_state = 0)\n",
    "\n",
    "# Calling the function\n",
    "classification_model(X_train_scale, X_test_scale, df_test_scale, Model, Model_string='LogisticRegression', col='all_features', bst_prms='NO')\n",
    "\n",
    "# Assign f1 score to a variable for the model comparison \n",
    "# LR1 = score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.1.2 - Logistic Regression with Hyperparameter Tuning (all features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.7420303166024437\n",
      "Confusion Matrix is:\n",
      " [[150  50]\n",
      " [ 55 152]]\n",
      "Tuned Model Parameters: {'C': 1}\n",
      "CSV file is created successfully\n"
     ]
    }
   ],
   "source": [
    "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% RUN %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "\n",
    "# Set up parameters\n",
    "param_grid = {'C': np.arange(1, 1000)}\n",
    "\n",
    "# Function for hyperparameter tuning to logistic regression with all features\n",
    "Model = GridSearchCV(LogisticRegression(random_state = 0), param_grid, cv=5, scoring = 'f1_weighted')\n",
    "\n",
    "# Calling the function\n",
    "classification_model(X_train_scale, X_test_scale, df_test_scale, Model, Model_string='LogisticRegression', col='tuned_all_features', bst_prms='YES')\n",
    "\n",
    "# Assign f1 score to a variable for the model comparison \n",
    "# LR2 = score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.1.3 - Logistic Regression with PCA features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.7420303166024437\n",
      "Confusion Matrix is:\n",
      " [[150  50]\n",
      " [ 55 152]]\n",
      "CSV file is created successfully\n"
     ]
    }
   ],
   "source": [
    "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% RUN %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "\n",
    "# Function for logistic regression with PCA features\n",
    "Model = LogisticRegression(random_state = 0)\n",
    "\n",
    "# Calling the function\n",
    "classification_model(X_train_pca, X_test_pca, df_test_pca, Model, Model_string='LogisticRegression', col='PCA_features', bst_prms='NO')\n",
    "\n",
    "# Assign f1 score to a variable for the model comparison \n",
    "# LR3 = score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.1.4 - Logistic Regression with Hyperparameter Tuning (PCA features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.7420303166024437\n",
      "Confusion Matrix is:\n",
      " [[150  50]\n",
      " [ 55 152]]\n",
      "Tuned Model Parameters: {'C': 1}\n",
      "CSV file is created successfully\n"
     ]
    }
   ],
   "source": [
    "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% RUN %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "\n",
    "# Set up parameters\n",
    "param_grid={'C': np.arange(1, 100)}\n",
    "\n",
    "# Functions for tuning logistic regression with pca features\n",
    "Model = GridSearchCV(LogisticRegression(random_state = 0), param_grid, cv = 5, scoring = 'f1_weighted')\n",
    "\n",
    "# Calling the function\n",
    "score = classification_model(X_train_pca, X_test_pca, df_test_pca, Model, Model_string='LogisticRegression',col='tuned_PCA_features', bst_prms='YES')\n",
    "\n",
    "# Assign f1 score to a variable for the model comparison \n",
    "# LR4 = score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 - Decision Tree Classification\n",
    "##### ==================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.2.1 - Decision Tree Classification with all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.9107119907119908\n",
      "Confusion Matrix is:\n",
      " [[164  36]\n",
      " [  0 207]]\n",
      "CSV file is created successfully\n"
     ]
    }
   ],
   "source": [
    "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% RUN %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "\n",
    "# Function for decision tree classification model with all features\n",
    "Model = DecisionTreeClassifier(criterion = 'gini', random_state = 0)\n",
    "\n",
    "# Calling the function\n",
    "score = classification_model(X_train_scale, X_test_scale, df_test_scale, Model, Model_string='DecisionTreeClassifier',col='all_features', bst_prms='NO')\n",
    "\n",
    "# Assign f1 score to a variable for the model comparison\n",
    "# DTC1 = score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.2.2 - Decision Tree Classification with Hyperparameter Tuning (all features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.9182665100226317\n",
      "Confusion Matrix is:\n",
      " [[167  33]\n",
      " [  0 207]]\n",
      "Tuned Model Parameters: {'criterion': 'entropy', 'max_depth': 27.0, 'min_samples_leaf': 1}\n",
      "CSV file is created successfully\n"
     ]
    }
   ],
   "source": [
    "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% RUN %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "\n",
    "# Setup the parameters and distributions to sample from: param_dist\n",
    "param_dist = {\"max_depth\": np.linspace(1, 32, 32, endpoint=True),\n",
    "              \"min_samples_leaf\": randint(1, 9),\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "# Function for hyperparameter tuning to decision tree classification with all features\n",
    "Model = RandomizedSearchCV(DecisionTreeClassifier(criterion = 'gini', random_state = 0), param_dist, cv=5, scoring = 'f1_weighted')\n",
    "\n",
    "# Calling the function\n",
    "classification_model(X_train_scale, X_test_scale, df_test_scale, Model, Model_string='DecisionTreeClassifier',col='tuned_all_features', bst_prms='YES')\n",
    "\n",
    "# Assign f1 score to a variable for the model comparison\n",
    "# DTC2 = score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.2.3 - Decision Tree Classification with PCA features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.9157517041738352\n",
      "Confusion Matrix is:\n",
      " [[166  34]\n",
      " [  0 207]]\n",
      "CSV file is created successfully\n"
     ]
    }
   ],
   "source": [
    "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% RUN %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "\n",
    "# Function for decision tree classification with PCA features\n",
    "Model = DecisionTreeClassifier(criterion = 'gini', random_state = 0)\n",
    "\n",
    "# Calling the function\n",
    "classification_model(X_train_pca, X_test_pca, df_test_pca, Model, Model_string='DecisionTreeClassifier',col='PCA_features', bst_prms='NO')\n",
    "\n",
    "# Assign f1 score to a variable for the model comparison \n",
    "# DTC3 = score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.2.4 - Decision Tree with Hyperparameter Tuning (PCA features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.9357848611859307\n",
      "Confusion Matrix is:\n",
      " [[174  26]\n",
      " [  0 207]]\n",
      "Tuned Model Parameters: {'criterion': 'entropy', 'max_depth': 14.0, 'min_samples_leaf': 1}\n",
      "CSV file is created successfully\n"
     ]
    }
   ],
   "source": [
    "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% RUN %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "\n",
    "# Setup the parameters and distributions to sample from: param_dist\n",
    "param_dist = {\"max_depth\": np.linspace(1, 32, 32, endpoint = True),\n",
    "              \"min_samples_leaf\": randint(1, 9),\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "# Functions for tuning decision trees with pca features\n",
    "Model = RandomizedSearchCV(DecisionTreeClassifier(criterion = 'gini', random_state = 0), param_dist, cv = 5, scoring = 'f1_weighted', random_state = 0)\n",
    "\n",
    "# Calling the function\n",
    "classification_model(X_train_pca, X_test_pca, df_test_pca, Model, Model_string='DecisionTreeClassifier',col='tuned_PCA_features', bst_prms='YES')\n",
    "\n",
    "# Assign f1 score to a variable for the model comparison \n",
    "# DTC4 = score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 - Random Forest Classification\n",
    "==================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.3.1 - Random Forest Classification with all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.9532763085573664\n",
      "Confusion Matrix is:\n",
      " [[186  14]\n",
      " [  5 202]]\n",
      "CSV file is created successfully\n"
     ]
    }
   ],
   "source": [
    "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% RUN %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "\n",
    "# Function for Random Forest Classification model with all features\n",
    "Model = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "\n",
    "# Calling the function\n",
    "score = classification_model(X_train_scale, X_test_scale, df_test_scale, Model, Model_string='RFC',col='all_features', bst_prms='NO')\n",
    "\n",
    "# Assign f1 score to a variable for model comparison\n",
    "# RFC1 = score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.3.2 - Random Forest Classification with Hyperparameter Tuning (all features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   36.5s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  5.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.9680531798575398\n",
      "Confusion Matrix is:\n",
      " [[192   8]\n",
      " [  5 202]]\n",
      "Tuned Model Parameters: {'n_estimators': 336, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 20}\n",
      "CSV file is created successfully\n"
     ]
    }
   ],
   "source": [
    "# Setup the parameters and distributions to sample from: param_dist\n",
    "n_estimators = [int(x) for x in np.linspace(start = 10, stop = 500, num = 10)]\n",
    "max_features = ['auto', 'sqrt']\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf}\n",
    "\n",
    "# Function for hyperparameter tuning to random forest classification with all features\n",
    "Model = RandomizedSearchCV(estimator = RandomForestClassifier(random_state = 0),\n",
    "                           param_distributions = random_grid, n_iter = 100, cv = 5,\n",
    "                           verbose=2, random_state=0, n_jobs = -1, scoring = 'f1_weighted')\n",
    "\n",
    "# Calling the function\n",
    "classification_model(X_train_scale, X_test_scale, df_test_scale, Model, Model_string='RandomForestClassifier', col='tuned_all_features', bst_prms = 'YES')\n",
    "\n",
    "# Assign f1 score to a variable for model comparison\n",
    "# RFC2 = score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.3.3 - Random Forest Classification with PCA features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.970512765110755\n",
      "Confusion Matrix is:\n",
      " [[193   7]\n",
      " [  5 202]]\n",
      "CSV file is created successfully\n"
     ]
    }
   ],
   "source": [
    "# Function for Random Forest Classification with PCA features\n",
    "Model = RandomForestClassifier(random_state=0)\n",
    "\n",
    "# Calling the function\n",
    "classification_model(X_train_pca, X_test_pca, df_test_pca, Model, Model_string='RandomForestClassifier',col='PCA_features', bst_prms = 'NO')\n",
    "\n",
    "# Assign f1 score to a variable for the model comparison \n",
    "# RFC3 = score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.3.4 - Random Forest with Hyperparameter Tuning (PCA features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    7.8s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   31.3s\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  1.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.9754299754299754\n",
      "Confusion Matrix is:\n",
      " [[195   5]\n",
      " [  5 202]]\n",
      "Tuned Model Parameters: {'n_estimators': 80, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 110}\n",
      "CSV file is created successfully\n"
     ]
    }
   ],
   "source": [
    "# Seting up parameters\n",
    "n_estimators = [int(x) for x in np.linspace(start = 10, stop = 100, num = 10)]\n",
    "max_features = ['auto', 'sqrt']\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf}\n",
    "\n",
    "# Functions for tuning Random Forest classification with pca features\n",
    "Model = RandomizedSearchCV(estimator = RandomForestClassifier(), \n",
    "                           param_distributions = random_grid,\n",
    "                           n_iter = 100, cv = 5, verbose=2, random_state=0,\n",
    "                           n_jobs = -1, scoring = 'f1_weighted')\n",
    "\n",
    "# Calling the function\n",
    "score = classification_model(X_train_pca, X_test_pca, df_test_pca, Model, Model_string='RFC', col='tuned_PCA_features', bst_prms = 'YES')\n",
    "\n",
    "# Assign f1 score to a variable for the model comparison \n",
    "RFC4 = score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 - K-NN Classification\n",
    "##### ==================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.4.1 - K-NN Classification with all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.8015822015822015\n",
      "Confusion Matrix is:\n",
      " [[142  58]\n",
      " [ 22 185]]\n",
      "CSV file is created successfully\n"
     ]
    }
   ],
   "source": [
    "# Function for K-NN classification with all features\n",
    "Model = KNeighborsClassifier()\n",
    "\n",
    "# Calling the function\n",
    "classification_model(X_train_scale, X_test_scale, df_test_scale, Model, Model_string='KNeighborsClassifier', col='all_features', bst_prms = 'NO')\n",
    "\n",
    "# Assign f1 score to a variable for the model comparison\n",
    "# KNC1 = score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.4.2 - K-NN Classification with Hyperparameter Tuning (all features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.9407655449625721\n",
      "Confusion Matrix is:\n",
      " [[176  24]\n",
      " [  0 207]]\n",
      "Tuned Model Parameters: {'n_neighbors': 1}\n",
      "CSV file is created successfully\n"
     ]
    }
   ],
   "source": [
    "# Set up parameters\n",
    "param_grid={'n_neighbors': np.arange(1, 50)}\n",
    "\n",
    "# Function for hyperparameter tuning to K-NN classification with all features\n",
    "Model = GridSearchCV(KNeighborsClassifier(), param_grid, cv = 5, scoring = 'f1_weighted')\n",
    "\n",
    "# Calling the function\n",
    "classification_model(X_train_scale, X_test_scale, df_test_scale, Model, Model_string='KNeighborsClassifier', col='tuned_all_features', bst_prms = 'YES')\n",
    "\n",
    "# Assign f1 score to a variable for the model comparison \n",
    "# KNC2 = score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.4.3 - K-NN Classification with PCA features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.8015822015822015\n",
      "Confusion Matrix is:\n",
      " [[142  58]\n",
      " [ 22 185]]\n",
      "CSV file is created successfully\n"
     ]
    }
   ],
   "source": [
    "# Function for K-NN Classification with PCA features\n",
    "Model = KNeighborsClassifier()\n",
    "\n",
    "# Calling the function\n",
    "classification_model(X_train_pca, X_test_pca, df_test_pca, Model, Model_string='KNeighborsClassifier', col='PCA_features', bst_prms = 'NO')\n",
    "\n",
    "# Assign f1 score to a variable for the model comparison \n",
    "# KNC3 = score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.4.4 - K-NN with Hyperparameter Tuning (PCA features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.9407655449625721\n",
      "Confusion Matrix is:\n",
      " [[176  24]\n",
      " [  0 207]]\n",
      "Tuned Model Parameters: {'n_neighbors': 1}\n",
      "CSV file is created successfully\n"
     ]
    }
   ],
   "source": [
    "# Setting up parameters\n",
    "param_grid={'n_neighbors': np.arange(1, 50)}\n",
    "\n",
    "# Functions for tuning K-NN classification with pca features\n",
    "Model = GridSearchCV(KNeighborsClassifier(), param_grid, cv = 5, scoring = 'f1_weighted')\n",
    "\n",
    "# Calling the function\n",
    "classification_model(X_train_pca, X_test_pca, df_test_pca, Model, Model_string='KNeighborsClassifier', col='tuned_PCA_features', bst_prms = 'YES')\n",
    "\n",
    "# Assign f1 score to a variable for the model comparison \n",
    "# KNC4 = score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 - Support Vector Machine(SVM) Classification\n",
    "##### ==================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.5.1 - SVM Classification with all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.7566921397860884\n",
      "Confusion Matrix is:\n",
      " [[156  44]\n",
      " [ 55 152]]\n",
      "CSV file is created successfully\n"
     ]
    }
   ],
   "source": [
    "# Function for SVM classifier with all features\n",
    "Model = SVC(kernel = 'linear', random_state = 0, probability=True)\n",
    "\n",
    "# Calling the function\n",
    "classification_model(X_train_scale, X_test_scale, df_test_scale, Model,  Model_string='SVM', col='all_features', bst_prms = 'NO')\n",
    "\n",
    "# Assign f1 score to a variable for the model comparison\n",
    "# SVC1 = score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.5.2 - SVM Classification with Hyperparameter Tuning (all features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.7542552541345104\n",
      "Confusion Matrix is:\n",
      " [[155  45]\n",
      " [ 55 152]]\n",
      "Tuned Model Parameters: {'C': 0.1, 'gamma': 0.001}\n",
      "CSV file is created successfully\n"
     ]
    }
   ],
   "source": [
    "# Specify the hyperparameter space\n",
    "CS = [0.001, 0.01, 0.1, 1, 10]\n",
    "gammas = [0.001, 0.01, 0.1, 1]\n",
    "param_grid = {'C': CS, 'gamma' : gammas}\n",
    "\n",
    "# Function for hyperparameter tuning to SVM classification with all features\n",
    "Model = GridSearchCV(SVC(kernel='linear', probability=True), param_grid, cv = 5, scoring = 'f1_weighted')\n",
    "\n",
    "# Calling the function\n",
    "classification_model(X_train_scale, X_test_scale, df_test_scale, Model, Model_string='SVM', col='tuned_all_features', bst_prms = 'YES')\n",
    "\n",
    "# Assign f1 score to a variable for the model comparison\n",
    "# SVC2 = score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.5.3 - SVM Classification with PCA features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.8865403590174232\n",
      "Confusion Matrix is:\n",
      " [[166  34]\n",
      " [ 12 195]]\n",
      "CSV file is created successfully\n"
     ]
    }
   ],
   "source": [
    "# Function for SVM classification with PCA features\n",
    "Model = SVC(probability=True)\n",
    "\n",
    "# Calling the function\n",
    "classification_model(X_train_pca, X_test_pca, df_test_pca, Model, Model_string='SVM', col='PCA_features', bst_prms = 'NO')\n",
    "\n",
    "# Assign f1 score to a variable for the model comparison\n",
    "# SVC3 = score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.5.4 - SVM with Hyperparameter Tuning (PCA features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.7542552541345104\n",
      "Confusion Matrix is:\n",
      " [[155  45]\n",
      " [ 55 152]]\n",
      "Tuned Model Parameters: {'C': 0.1, 'gamma': 0.001}\n",
      "CSV file is created successfully\n"
     ]
    }
   ],
   "source": [
    "# Specify the hyperparameter space\n",
    "CS = [0.001, 0.01, 0.1, 1, 10]\n",
    "gammas = [0.001, 0.01, 0.1, 1]\n",
    "param_grid = {'C': CS, 'gamma' : gammas}\n",
    "\n",
    "# Functions for tuning SVM classification with pca features\n",
    "Model = GridSearchCV(SVC(kernel='linear', probability=True), param_grid, cv=5, scoring = 'f1_weighted')\n",
    "\n",
    "# Calling the function\n",
    "classification_model(X_train_pca, X_test_pca, df_test_pca, Model, Model_string='SVM', col='tuned_PCA_features', bst_prms = 'YES')\n",
    "\n",
    "# Assign f1 score to a variable for the model comparison\n",
    "# SVC4 = score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 - Kernel Support Vector Machine(SVM) Classification\n",
    "##### ==================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.6.1 - Kernel SVM Classification with all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.8865403590174232\n",
      "Confusion Matrix is:\n",
      " [[166  34]\n",
      " [ 12 195]]\n",
      "CSV file is created successfully\n"
     ]
    }
   ],
   "source": [
    "# Function for Kernal SVM classifier with all features\n",
    "Model = SVC(kernel = 'rbf', random_state = 0, probability=True)\n",
    "\n",
    "# Calling the function\n",
    "classification_model(X_train_scale, X_test_scale, df_test_scale, Model, Model_string='KernelSVM', col='all_features', bst_prms = 'NO')\n",
    "\n",
    "# Assign f1 score to a variable for the model comparison\n",
    "# KSVC1 = score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.6.2 - Kernel SVM Classification with Hyperparameter Tuning (all features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.9877157293620212\n",
      "Confusion Matrix is:\n",
      " [[200   0]\n",
      " [  5 202]]\n",
      "Tuned Model Parameters: {'C': 1, 'gamma': 1}\n",
      "CSV file is created successfully\n"
     ]
    }
   ],
   "source": [
    "# Specify the hyperparameter space\n",
    "CS = [0.001, 0.01, 0.1, 1, 10]\n",
    "gammas = [0.001, 0.01, 0.1, 1]\n",
    "param_grid = {'C': CS, 'gamma' : gammas}\n",
    "\n",
    "# Function for hyperparameter tuning to Kernel SVM classification with all features\n",
    "Model = GridSearchCV(SVC(kernel='rbf', probability=True), param_grid, cv=5, scoring = 'f1_weighted')\n",
    "\n",
    "# Calling the function\n",
    "classification_model(X_train_scale, X_test_scale, df_test_scale, Model, Model_string='KernelSVM', col='tuned_all_features', bst_prms = 'YES')\n",
    "\n",
    "# Assign f1 score to a variable for the model comparison\n",
    "# KSVC2 = score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.6.3 - Kernel SVM Classification with PCA features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.8865403590174232\n",
      "Confusion Matrix is:\n",
      " [[166  34]\n",
      " [ 12 195]]\n",
      "CSV file is created successfully\n"
     ]
    }
   ],
   "source": [
    "# Function for Kernel SVM classification with PCA features\n",
    "Model = SVC(kernel='rbf', random_state = 0, probability=True)\n",
    "\n",
    "# Calling the function\n",
    "classification_model(X_train_pca, X_test_pca, df_test_pca, Model, Model_string='KernelSVM', col='PCA_features', bst_prms = 'NO')\n",
    "\n",
    "# Assign f1 score to a variable for the model comparison\n",
    "# KSVC3 = score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.6.4 - Kernel SVM with Hyperparameter Tuning (PCA features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.9877157293620212\n",
      "Confusion Matrix is:\n",
      " [[200   0]\n",
      " [  5 202]]\n",
      "Tuned Model Parameters: {'C': 1, 'gamma': 1}\n",
      "CSV file is created successfully\n"
     ]
    }
   ],
   "source": [
    "# Specify the hyperparameter space\n",
    "CS = [0.001, 0.01, 0.1, 1, 10]\n",
    "gammas = [0.001, 0.01, 0.1, 1]\n",
    "param_grid = {'C': CS, 'gamma' : gammas}\n",
    "\n",
    "# Functions for tuning SVM classification with pca features\n",
    "Model = GridSearchCV(SVC(kernel='rbf', probability=True), param_grid,cv = 5, scoring = 'f1_weighted')\n",
    "\n",
    "# Calling the function\n",
    "classification_model(X_train_pca, X_test_pca, df_test_pca, Model, Model_string='KernelSVM', col='tuned_PCA_features', bst_prms = 'YES')\n",
    "\n",
    "# Assign f1 score to a variable for the model comparison\n",
    "# KSVC4 = score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.7 - Naive Bayes Classification\n",
    "==================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.7.1 - Naive Bayes Classification with all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.6149813606710158\n",
      "Confusion Matrix is:\n",
      " [[ 98 102]\n",
      " [ 52 155]]\n",
      "CSV file is created successfully\n"
     ]
    }
   ],
   "source": [
    "# Function for Naive Bayes Classifier with all features\n",
    "Model = GaussianNB()\n",
    "\n",
    "# Calling the function\n",
    "classification_model(X_train_scale, X_test_scale, df_test_scale, Model, Model_string='GaussianNB', col='all_features', bst_prms = 'NO')\n",
    "\n",
    "# Assign f1 score to a variable for the model comparison\n",
    "# NBC1 = score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.7.2 - Naive Bayes Classification with Hyperparameter Tuning (all features)\n",
    "Not checking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.7.3 - Naive Bayes Classification with PCA features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.72338094049324\n",
      "Confusion Matrix is:\n",
      " [[131  69]\n",
      " [ 43 164]]\n",
      "CSV file is created successfully\n"
     ]
    }
   ],
   "source": [
    "# Function for Naive Bayes Classification with PCA features\n",
    "Model = GaussianNB()\n",
    "\n",
    "# Calling the function\n",
    "classification_model(X_train_pca, X_test_pca, df_test_pca, Model, Model_string='GaussianNB', col='PCA_features', bst_prms = 'NO')\n",
    "\n",
    "# Assign f1 score to a variable for the model comparison\n",
    "# NBC2 = score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.7.4 - Naive Bayes Classification with Hyperparameter Tuning (PCA features)\n",
    "Not checking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-8 Gradient Boosting Classification \n",
    "==================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.8.1 - Gradient Boosting Classification with all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.9090117587696083\n",
      "Confusion Matrix is:\n",
      " [[177  23]\n",
      " [ 14 193]]\n",
      "CSV file is created successfully\n"
     ]
    }
   ],
   "source": [
    "# Function for Gradient Boosting Classifier with all features\n",
    "Model = GradientBoostingClassifier()\n",
    "\n",
    "# Calling the function\n",
    "classification_model(X_train_scale, X_test_scale, df_test_scale, Model, Model_string='GradientBoostingClassifier', col='all_features', bst_prms = 'NO')\n",
    "\n",
    "# Assign f1 score to a variable for the model comparison\n",
    "# GBC1 = score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.8.2 - Gradient Boosting Classification with Hyperparameter Tuning (all features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.9409270029578973\n",
      "Confusion Matrix is:\n",
      " [[181  19]\n",
      " [  5 202]]\n",
      "CSV file is created successfully\n"
     ]
    }
   ],
   "source": [
    "# Setting Parameters\n",
    "gb_params ={\n",
    "    'n_estimators': 1500,\n",
    "    'max_features': 0.9,\n",
    "    'learning_rate' : 0.25,\n",
    "    'max_depth': 2,\n",
    "    'min_samples_leaf': 3,\n",
    "    'subsample': 1,\n",
    "    'max_features' : 'sqrt',\n",
    "    'random_state' : 0\n",
    "}\n",
    "\n",
    "# Instantiate Gradient Boosting classifier: gb\n",
    "Model = GradientBoostingClassifier(**gb_params)\n",
    "\n",
    "# Calling the function\n",
    "classification_model(X_train_scale, X_test_scale, df_test_scale, Model, Model_string='GradientBoostingClassifier', col='tuned_all_features', bst_prms = 'NO')\n",
    "\n",
    "# Assign f1 score to a variable for the model comparison\n",
    "# GBC2 = score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.8.3 - Gradient Boosting Classification with PCA features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.9458713832171071\n",
      "Confusion Matrix is:\n",
      " [[183  17]\n",
      " [  5 202]]\n",
      "CSV file is created successfully\n"
     ]
    }
   ],
   "source": [
    "# Function for Gradient Boosting Classification with PCA features\n",
    "Model = GradientBoostingClassifier()\n",
    "\n",
    "# Calling the function\n",
    "classification_model(X_train_pca, X_test_pca, df_test_pca, Model, Model_string='GradientBoostingClassifier', col='PCA_features', bst_prms = 'NO')\n",
    "\n",
    "# Assign f1 score to a variable for the model comparison\n",
    "# GBC3 = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model.fit(X_train_pca, Y_train)\n",
    "Y_test_pred = Model.predict(X_test_pca)\n",
    "df_test_pred = Model.predict(df_test_scale)\n",
    "df_test_pred_prob = Model.predict_proba(df_test_scale)\n",
    "print('score value: ', Model.score(X_test_pca, Y_test))\n",
    "print('f1_score value: ', f1_score(Y_test, Y_test_pred, average = 'weighted'))\n",
    "# print(\"Tuned Model Parameters: {}\".format(Model.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.8.4 - Gradient Boosting with Hyperparameter Tuning (PCA features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.9655407517254402\n",
      "Confusion Matrix is:\n",
      " [[186  14]\n",
      " [  0 207]]\n",
      "CSV file is created successfully\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting Parameters\n",
    "gb_params ={\n",
    "    'n_estimators': 1500,\n",
    "    'max_features': 0.9,\n",
    "    'learning_rate' : 0.25,\n",
    "    'max_depth': 2,\n",
    "    'min_samples_leaf': 3,\n",
    "    'subsample': 1,\n",
    "    'max_features' : 'sqrt',\n",
    "    'random_state' : 0\n",
    "}\n",
    "\n",
    "# Instantiate Gradient Boosting classifier: gb\n",
    "Model = GradientBoostingClassifier(**gb_params)\n",
    "\n",
    "# Calling the function\n",
    "classification_model(X_train_pca, X_test_pca, df_test_pca, Model, Model_string='GradientBoostingClassifier', col='tuned_PCA_features', bst_prms = 'NO')\n",
    "\n",
    "# Assign f1 score to a variable for the model comparison\n",
    "# GBC4 = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.9 - ADA Boost Classification\n",
    "==================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.9.1 - ADA Boost Classification with all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.7763074718567342\n",
      "Confusion Matrix is:\n",
      " [[161  39]\n",
      " [ 52 155]]\n",
      "CSV file is created successfully\n"
     ]
    }
   ],
   "source": [
    "# Function for ADA Boost Classifier with all features\n",
    "Model = AdaBoostClassifier()\n",
    "\n",
    "# Calling the function\n",
    "classification_model(X_train_scale, X_test_scale, df_test_scale, Model, Model_string='AdaBoostClassifier', col='all_features', bst_prms = 'NO')\n",
    "\n",
    "# Assign f1 score to a variable for the model comparison\n",
    "# ADABC1 = score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.9.2 - ADA Boost Classification with Hyperparameter Tuning (all features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.791003440337619\n",
      "Confusion Matrix is:\n",
      " [[165  35]\n",
      " [ 50 157]]\n",
      "CSV file is created successfully\n"
     ]
    }
   ],
   "source": [
    "# Instantiate ADA Boosting classifier: abc\n",
    "Model = AdaBoostClassifier(n_estimators= 150, learning_rate = 0.2, random_state = 0)\n",
    "\n",
    "# Calling the function\n",
    "classification_model(X_train_scale, X_test_scale, df_test_scale, Model, Model_string='AdaBoostClassifier', col='tuned_all_features', bst_prms = 'NO')\n",
    "\n",
    "# Assign f1 score to a variable for the model comparison\n",
    "# ADABC2 = score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.9.3 - ADA Boost Classification with PCA features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.8280202123847972\n",
      "Confusion Matrix is:\n",
      " [[166  34]\n",
      " [ 36 171]]\n",
      "CSV file is created successfully\n"
     ]
    }
   ],
   "source": [
    "# Function for ADA Boost Classification with PCA features\n",
    "Model = AdaBoostClassifier()\n",
    "\n",
    "# Calling the function\n",
    "classification_model(X_train_pca, X_test_pca, df_test_pca, Model, Model_string='AdaBoostClassifier', col='PCA_features', bst_prms = 'NO')\n",
    "\n",
    "# Assign f1 score to a variable for the model comparison\n",
    "# ADABC3 = score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.9.4 - ADA Boost with Hyperparameter Tuning (PCA features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.8520971526064905\n",
      "Confusion Matrix is:\n",
      " [[160  40]\n",
      " [ 20 187]]\n",
      "CSV file is created successfully\n"
     ]
    }
   ],
   "source": [
    "# Instantiate ADA Boosting classifier: abc\n",
    "Model = AdaBoostClassifier(n_estimators= 250, learning_rate = 0.25, random_state = 0)\n",
    "\n",
    "# Calling the function\n",
    "classification_model(X_train_pca, X_test_pca, df_test_pca, Model, Model_string='AdaBoostClassifier', col='tuned_PCA_features', bst_prms = 'NO')\n",
    "\n",
    "# Assign f1 score to a variable for the model comparison\n",
    "# ADABC4 = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_scores1 =  compare_scores\n",
    "for col in compare_scores.columns:\n",
    "    for row in compare_scores.index:\n",
    "        compare_scores1[col][row] = compare_scores[col][row]\n",
    "compare_scores =  compare_scores1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all_features</th>\n",
       "      <th>tuned_all_features</th>\n",
       "      <th>PCA_features</th>\n",
       "      <th>tuned_PCA_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.742030</td>\n",
       "      <td>0.742030</td>\n",
       "      <td>0.742030</td>\n",
       "      <td>0.742030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.910712</td>\n",
       "      <td>0.918267</td>\n",
       "      <td>0.915752</td>\n",
       "      <td>0.935785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.968053</td>\n",
       "      <td>0.970513</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.940766</td>\n",
       "      <td>0.801582</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.754255</td>\n",
       "      <td>0.886540</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KernelSVM</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.987716</td>\n",
       "      <td>0.886540</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianNB</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.723381</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingClassifier</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.940927</td>\n",
       "      <td>0.945871</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.791003</td>\n",
       "      <td>0.828020</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            all_features  tuned_all_features  PCA_features  \\\n",
       "LogisticRegression              0.742030            0.742030      0.742030   \n",
       "DecisionTreeClassifier          0.910712            0.918267      0.915752   \n",
       "RandomForestClassifier          0.000000            0.968053      0.970513   \n",
       "KNeighborsClassifier            0.000000            0.940766      0.801582   \n",
       "SVM                             0.000000            0.754255      0.886540   \n",
       "KernelSVM                       0.000000            0.987716      0.886540   \n",
       "GaussianNB                      0.000000            0.000000      0.723381   \n",
       "GradientBoostingClassifier      0.000000            0.940927      0.945871   \n",
       "AdaBoostClassifier              0.000000            0.791003      0.828020   \n",
       "\n",
       "                            tuned_PCA_features  \n",
       "LogisticRegression                    0.742030  \n",
       "DecisionTreeClassifier                0.935785  \n",
       "RandomForestClassifier                0.000000  \n",
       "KNeighborsClassifier                  0.000000  \n",
       "SVM                                   0.000000  \n",
       "KernelSVM                             0.000000  \n",
       "GaussianNB                            0.000000  \n",
       "GradientBoostingClassifier            0.000000  \n",
       "AdaBoostClassifier                    0.000000  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_scores1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "compare_scores.to_csv('compare_scores.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Model Comparison\n",
    "==================================================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of model f1 scores to compare\n",
    "results={'Logistic Regression': [LR1, LR2, LR3, LR4], \n",
    "         'Decision Tree': [DTC1, DTC2, DTC3, DTC4], \n",
    "         'Random Forest': [RFC1, RFC2, RFC3, RFC4], \n",
    "         'K-NN': [KNC1, KNC2, KNC3, KNC4], \n",
    "         'SVM': [SVC1, SVC2, SVC3, SVC4], \n",
    "         'Kernel SVM': [KSVC1, KSVC2, KSVC3, KSVC4],\n",
    "         'Naive Bayes': [NBC1, NBC1, NBC2, NBC2], \n",
    "         'Gradient Boosting': [GBC1, GBC2, GBC3, GBC4], \n",
    "         'ADA Boosting': [ADABC1, ADABC2, ADABC3, ADABC4]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating model comparison dataframe\n",
    "comparison = pd.DataFrame.from_dict(results, orient='index')\n",
    "comparison.columns = ['all_features', 'tuned_all_features', 'PCA_features', 'tuned_PCA_features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the total improvement on the f1 score\n",
    "\n",
    "list1 = []\n",
    "for i in comparison.index:\n",
    "    max_val = max(comparison.all_features[i], comparison.tuned_all_features[i], comparison.PCA_features[i], comparison.tuned_PCA_features[i])\n",
    "    e = (max_val / comparison.all_features[i]) - 1\n",
    "    list1.append(float(\"%.4f\" % e))\n",
    "\n",
    "comparison['Total Improvement(%)'] = list1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models Compare List\n",
    "comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in comparison.columns:\n",
    "    print('Optimum value in '+col+' is :' + comparison[comparison['all_features']==comparison['all_features'].max()].index[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Result:\n",
    "Best method which we are getting best accurate score is '**Random Forest**'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison of ML Classifiers with Effects of Feature Engineering\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "r = [0,1,2,3,4,5,6,7,8]\n",
    "\n",
    "# From raw value to percentage\n",
    "A = comparison.iloc[:,0]\n",
    "B = comparison.iloc[:,1]\n",
    "C = comparison.iloc[:,2]\n",
    "D = comparison.iloc[:,3]\n",
    "\n",
    "# plot\n",
    "barWidth = 0.85\n",
    "names = ('Logistic Regression', 'Decision Tree', 'Random Forest', 'K-NN', 'SVM', \n",
    "         'Kernel SVM', 'Naive Bayes', 'Gradient Boosting', 'ADA Boosting')\n",
    "fig = plt.figure(figsize=(15,8))\n",
    "\n",
    "# Create green Bars\n",
    "plt.plot(r, A, color='green')\n",
    "\n",
    "# Create orange Bars\n",
    "plt.plot(r, B, color='red')\n",
    "\n",
    "# Create blue Bars\n",
    "plt.plot(r, C, color='blue')\n",
    "\n",
    "# Create purple Bars\n",
    "plt.plot(r, D, color='purple')\n",
    " \n",
    "# Custom x axis\n",
    "plt.xticks(r, names, fontsize='large')\n",
    "plt.yticks(np.arange(0.67,0.78,0.1))\n",
    "plt.xlabel(\"ML Classifiers\", fontsize='x-large')\n",
    "plt.ylabel(\"Future Engeneering\", fontsize='x-large')\n",
    "plt.title(\"Comparison of ML Classifiers with Effects of Future Engeneering\", fontsize='x-large')\n",
    "\n",
    "green = mpatches.Patch(color='green', label='all_features')\n",
    "orange = mpatches.Patch(color='red', label='tuned_all_features')\n",
    "blue = mpatches.Patch(color='blue', label='PCA_features')\n",
    "purple = mpatches.Patch(color='purple', label='tuned_PCA_features')\n",
    "plt.legend(handles=[green, orange, blue, purple], loc=4)\n",
    "\n",
    "# Show graphic\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Handling Target Class Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the hyperparameter space\n",
    "CS = [0.001, 0.01, 0.1, 1, 10]\n",
    "gammas = [0.001, 0.01, 0.1, 1]\n",
    "param_grid = {'C': CS, 'gamma' : gammas}\n",
    "\n",
    "# Instantiate Support Vector Machine classifier: svm\n",
    "Model = GridSearchCV(SVC(kernel='linear'), param_grid, cv=5, scoring = 'f1_weighted')\n",
    "\n",
    "'''# Calling the function\n",
    "score = classification_model(X_train_pca, X_test_pca, Model, RG='NO')\n",
    "\n",
    "# Assign f1 score to a variable for the model comparison\n",
    "ADABC4 = score'''\n",
    "\n",
    "\n",
    "# Fit to the training set\n",
    "Model.fit(X_train_pca, Y_train)\n",
    "\n",
    "# Predict the labels of the test set: y_pred\n",
    "Y_pred = Model.predict(X_test)\n",
    "\n",
    "# Compute and print metrics\n",
    "print(\"f1 score: {}\".format(Model.score(X_test, Y_test)))\n",
    "print(\"Tuned Model Parameters: {}\".format(Model.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Conclusion\n",
    "==================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6.1 - Most Important Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coefficients of feature importance (values for dictionary)\n",
    "svr = SVC(kernel='linear', C = 0.1, gamma = 0.001)\n",
    "clf = svr.fit(X_train, Y_train)\n",
    "clfc = clf.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "value = functools.reduce(lambda x, y: x+y, clfc)\n",
    "values = [x for x in value]\n",
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df3.drop('Attrition', axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Dictionary for feature importance - keys and values\n",
    "idx = X_train.columns\n",
    "keys = [str(x) for x in idx.tolist()]\n",
    "pairs = {keys[i]: values[i] for i in range(len(keys))}\n",
    "pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting feature importance for SVM model\n",
    "names = list(pairs.keys())\n",
    "values = list(pairs.values())\n",
    "\n",
    "plt.figure(figsize=(18,14))\n",
    "plt.barh(range(len(pairs)), values, tick_label = names, color = 'red')\n",
    "plt.title('Feature Importance in Model', fontsize = 25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Applying best model \"Random Forest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.drop(['Id', 'Behaviour', 'EmployeeNumber', 'PerformanceRating'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying Lable encoding\n",
    "# ===========================\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "LE = LabelEncoder()\n",
    "\n",
    "# Transforming non-numeric columns into numerical columns in Training Data Frame\n",
    "for column in df_test.columns:\n",
    "    if df_test[column].dtype == object:\n",
    "        df_test[column] = LE.fit_transform(df_test[column])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying Feature Scaling\n",
    "# ===========================\n",
    "std_sclr = StandardScaler()\n",
    "X_scale = std_sclr.fit_transform(df_test)\n",
    "X_scale = pd.DataFrame(X_scale, columns=df_test.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying PCA by Extracting 24 features\n",
    "# ==================================\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 24)\n",
    "X_test_pca = pd.DataFrame(pca.fit_transform(X_scale))\n",
    "X_test_pca.columns = X_scale.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# APPLYING RANDOM FOREST MODEL\n",
    "# ==================================\n",
    "\n",
    "# Instantiate the classifier: model\n",
    "Model = RandomForestClassifier(random_state=0)\n",
    "\n",
    "# Fitting classifier to the Training set (all features)\n",
    "Model.fit(X_train_pca, Y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "Y_test_pca_pred_RFC = Model.predict(X_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Y_test_pca_pred_RFC_prob = Model.predict_proba(X_test_pca)[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Defining Data Frame for Sample Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_pca_pred_RFC_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_set = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission_RFC = df_test_set[['Id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_submission_RFC['Y_test_pca_pred_RFC'] = Y_test_pca_pred_RFC\n",
    "sample_submission_RFC['Attrition'] = Y_test_pca_pred_RFC_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample_submission_RFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission_RFC.to_csv('sample_submission_RFC_02.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
